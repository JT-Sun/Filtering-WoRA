image_root: '/public/home/wangmiao/sjt_new/APTM-main/images/CUHK-PEDES/'
test_file: '/public/home/wangmiao/sjt_new/APTM-main/data/finetune/cuhk_test.json'
val_file: '/public/home/wangmiao/sjt_new/APTM-main/data/finetune/cuhk_val.json'
train_file:  ['/public/home/wangmiao/sjt_new/APTM-main/data/finetune/cuhk_train_filter_90percent.json']   #/public/home/wangmiao/sjt_new/APTM-main/data/finetune/cuhk_train.json


## Vision Encoder
vision_config: '/public/home/wangmiao/sjt_new/APTM-main/configs/config_swinB_384.json'
image_res: 384
patch_size: 32
h: 384
w: 128


## Text Encoder
text_config: '/public/home/wangmiao/sjt_new/APTM-main/configs/config_bert.json'
text_encoder: '/public/home/wangmiao/sjt_new/APTM-main/data/bert-base-uncased'


## Training
batch_size_train: 120
batch_size_test: 150
batch_size_test_text: 750

max_tokens: 56
max_words: 56

embed_dim: 256
temp: 0.07
k_test: 128


## mlm loss
mlm: True
mask_prob: 0.25
max_masks: 10
skipgram_prb: 0.2
skipgram_size: 3
mask_whole_word: True


## Other Settings
#optimizer: {opt: adamW, lr: 3e-5, weight_decay: 0.05, lr_mult: 2}
#schedular: {sched: warm_cosine, lr: 3e-5, epochs: 60, num_warmup_steps: 0.1}
optimizer: {opt: adamW, lr: 1e-7, weight_decay: 0.05, lr_mult: 2}
schedular: {sched: step, lr: 1e-7, epochs: 30, num_warmup_steps: 0.1}


pa100k: False
icfg_rstp: False

lr_2: True
load_params: False
load_pretrained: True

eda: True
eda_p: 1
erasing_p: 0.6
LabelSmooth: 0.1

#accelerator: {SYNCBN: false, FP16_OPT_LEVEL: O1, FP16_LOSS_SCALE: dynamic, RNG_SEED: 42, GRAD_ACCUMULATE_STEPS: 1, CLIP_GRAD_NORM: 1.0}
#fp16: True
box: False